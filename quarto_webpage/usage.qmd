---
title: "Usage"
---

``` console
straincascade -i input [-o output_directory] [-s seq_type] [-t threads] [-r result_type] [-m modules] [-f force_overwrite] [-d databases_directory] [-l locus_tag] [-h] [-v]

  -i  input               Input file or directory containing files (mandatory). Valid file formats include: `.fasta`, `.fa`, `.fastq`, `.fastq.gz`, `.fna`, and `.bam`. 
  -o  output_directory    Output directory (default: current working directory).
  -s  seq_type            Sequence type (default: pacbio-hifi). Options are: pacbio-raw | pacbio-corr | pacbio-hifi | nano-raw | nano-corr | nano-hq.
  -t  threads             Number of threads (default: 32).
  -m  modules             Modules to run (default: all). Use comma-separated or space-separated values for multiple modules.
  -r  result_type         Result type (default: main). Options are: all, main, R.
  -f  force_overwrite     Force overwrite existing results (default: yes). Options are: yes | no. (Note: 'no' does not always guarantee that nothing will be overwritten.)
  -d  databases_directory Path to databases directory (default: StrainCascade/databases).
                          Note: Custom database locations must maintain the same structure and naming of subdirectories/files as the default installation.
  -l  locus_tag           Specify your own locus tag for genome annotation (default: automatically generated). Must contain between 3 and 12 alphanumeric uppercase characters and start with a letter.
  -h                      Show this help message and exit.
  -v                      Show version information and exit.
```

## Quick start

To quickly run the StrainCascade pipeline on a sequencing sample from the command line, use the following minimal command:

``` bash
straincascade -i /path/to/your/input_file.bam
```

**Note:** Running the StrainCascade is resource-intensive and will overwhelm standard desktop or laptop computers. For optimal performance, we strongly recommend using a high-performance computing (HPC) environment.

For efficient execution, it's recommended to submit the pipeline as a SLURM `sbatch` job. Below is an example of a basic SLURM submission script. Be sure to adjust the `--partition` parameter to match your environment:

``` bash
#!/bin/bash #SBATCH 
--job-name="StrainCascade" 
#SBATCH --output=StrainCascade\_%j.out 
#SBATCH --cpus-per-task=32 
#SBATCH --mem=320G # 10GB per CPU for 32 CPUs 
#SBATCH --partition=your_partition

# Execute the job

straincascade -i /path/to/your/input_file.bam
```

To submit the script to your SLURM scheduler, use:

``` bash
sbatch your_script.sh
```
